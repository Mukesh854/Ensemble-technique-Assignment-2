{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21985ed7-8009-4ac5-8d21-655759880080",
   "metadata": {},
   "source": [
    "# Ensemble Technique Assignment-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b28ae9e-641a-4cf0-9db5-d5c7b89e4a07",
   "metadata": {},
   "source": [
    "Q1. How does bagging reduce overfitting in decision trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65d3e1-6b41-4871-88e2-76d75a644e40",
   "metadata": {},
   "source": [
    "Bagging reduces overfitting in decision trees by training multiple trees on different subsets of the data, then aggregating their predictions. This approach helps the model generalize better by reducing the impact of noise and outliers in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070ccc96-eee8-404c-8619-60de567f1c1b",
   "metadata": {},
   "source": [
    "Q2. What are the advantages and disadvantages of using different types of base learners in bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede15cc3-c39f-41e0-bf45-063bcb8aa557",
   "metadata": {},
   "source": [
    "Decision Trees:\n",
    "\n",
    "Advantages: Easy to interpret, handle various data types.\n",
    "\n",
    "Disadvantages: Prone to overfitting.\n",
    "\n",
    "SVM:\n",
    "\n",
    "Advantages: Effective in high dimensions, less prone to overfitting.\n",
    "\n",
    "Disadvantages: Computationally intensive, sensitive to kernel choice.\n",
    "\n",
    ". Advantages of Different Base Learners:\n",
    "\n",
    ". Diverse learners capture different patterns, enhancing generalization.\n",
    "\n",
    ". Each learner may excel in different parts of the data space.\n",
    "\n",
    ". Disadvantages of Different Base Learners:\n",
    "\n",
    ". Increased computational cost, especially for complex learners.\n",
    "\n",
    ". Decreased interpretability with complex models.\n",
    "\n",
    ". Hyperparameter tuning needed for optimal performance.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c15ee58-8c2f-4bb5-8358-1352c7e2363a",
   "metadata": {},
   "source": [
    "Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e33fc-3486-4dfc-93e5-476db5caec06",
   "metadata": {},
   "source": [
    "The choice of base learner affects how bagging impacts the bias-variance tradeoff. For high-variance learners like decision trees and neural networks, bagging reduces variance without substantially increasing bias. However, for high-bias learners like linear models, the reduction in bias may be less significant with bagging.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05737d3e-f3bc-480b-ab5c-155594a11c1e",
   "metadata": {},
   "source": [
    "Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feb2686-25c4-4804-991b-08942d01ae19",
   "metadata": {},
   "source": [
    "Yes, bagging can be used for both classification and regression tasks. In classification, it involves aggregating predictions from multiple classifiers using methods like majority voting. In regression, predictions from multiple models are averaged to produce the final result.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccba7afc-434c-4033-8d9b-780c67177919",
   "metadata": {},
   "source": [
    "Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e617bd-fef3-4db3-8d10-8dcfc09324a4",
   "metadata": {},
   "source": [
    "The ensemble size in bagging refers to the number of models trained on different subsets of data and aggregated. Increasing ensemble size typically improves performance up to a point, but there are diminishing returns. Start with a moderate size and adjust based on empirical validation, considering the trade-off between performance and computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6760620-2e13-4af6-8945-f553ee8ed1ae",
   "metadata": {},
   "source": [
    "Q6. Can you provide an example of a real-world application of bagging in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3dcfc0-7b77-457c-8222-c7900da4d26f",
   "metadata": {},
   "source": [
    "In credit risk assessment, bagging is used to improve predictive accuracy by training multiple models on different subsets of data and aggregating their predictions. This helps financial institutions make more reliable loan approval decisions, reducing the risk of defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d159a1de-4a17-471b-810b-3ad946d95fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
